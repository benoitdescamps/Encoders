{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import collections\n",
    "from functools import partial,reduce\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, Imputer, StandardScaler\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.decomposition import PCA, TruncatedSVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "def prepare_catergorical_data():\n",
    "    X,y = make_classification(n_samples=100, n_features=10)\n",
    "    X = np.array(list(map(lambda col:list(map(lambda x:int(10.0*np.abs(x)),col)),X)) )\n",
    "    return X,y\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation,Flatten\n",
    "from keras.layers.embeddings import Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#n_words = np.unique(X)\n",
    "#K = 10\n",
    "#input_array = X\n",
    "class my_model:\n",
    "    def __call__(self,X_col,K):\n",
    "        input_array = X_col\n",
    "        n_words = np.unique(input_array)\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(len(n_words), K, input_length=1))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "        print(model.summary())\n",
    "        return model\n",
    "# Train the model, iterating on the data in batches of 32 samples\n",
    "#model = my_model()(X,3)\n",
    "#model.fit(X, y, epochs=100, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.columns]\n",
    "\n",
    "\n",
    "class StringIndexer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.dictionaries = dict()\n",
    "        self.columns = list()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.columns = X.columns.values\n",
    "        for col in self.columns:\n",
    "            categories = np.unique(X[col])\n",
    "            self.dictionaries[col] = dict(zip(categories, range(len(categories))))\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        column_array = []\n",
    "        for col in self.columns:\n",
    "            dictionary = self.dictionaries[col]\n",
    "            na_value = len(dictionary) + 1\n",
    "            transformed_column = X[col].apply(lambda x: dictionary.get(x, na_value))\n",
    "            column_array.append(transformed_column.values.reshape(-1, 1))\n",
    "        return np.hstack(column_array)\n",
    "    \n",
    "def unravel_tree(dict_,name_key):\n",
    "    agg_dic =dict()\n",
    "    entry_name = name_key\n",
    "    def contains_dicts(dict_):\n",
    "        return reduce(lambda _check,item:_check | isinstance(item[1],dict),dict_.items(),False)\n",
    "    non_dictItems_dic = dict()\n",
    "    for item in dict_.items():\n",
    "        if not( isinstance(item[1],dict) ):\n",
    "            non_dictItems_dic.update({item[0]:item[1]})\n",
    "        else:\n",
    "            agg_dic.update(unravel_tree(item[1],name_key+'_'+str(item[0])) )\n",
    "    if non_dictItems_dic:\n",
    "        agg_dic.update({name_key:non_dictItems_dic})\n",
    "    return agg_dic\n",
    "def set_output(x):\n",
    "    if isinstance(x,dict):\n",
    "        return pd.DataFrame(x,index=[0])\n",
    "    return pd.DataFrame({'':x},index=[0])\n",
    "class FuncEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,columns = None,drop_old_columns = True,list_func=['mean','std','median']):\n",
    "        self.dictionaries = dict()\n",
    "        self.columns = list()\n",
    "        self.list_func = list_func\n",
    "        self.columns = columns\n",
    "        self.drop_old_columns = drop_old_columns\n",
    "    def fit(self, X, y=None):\n",
    "        \n",
    "        if self.columns is None:\n",
    "            self.columns = X.columns\n",
    "            \n",
    "        print(self.columns)\n",
    "        \n",
    "        X['TARGET'] = y\n",
    "        \n",
    "        for col in self.columns:\n",
    "            col_dict = dict()\n",
    "            func_dict = {\n",
    "                'mean':lambda x:x.mean(),\n",
    "                'std':lambda x:x.std(),\n",
    "                'median':lambda x:x.median()\n",
    "            }\n",
    "        \n",
    "            for func in self.list_func:\n",
    "                if isinstance(func,dict):\n",
    "                    for fun_name in func.keys():\n",
    "                        col_dict.update({fun_name:X[[col,'TARGET'] ]\\\n",
    "                                        .groupby([col])\\\n",
    "                                        .apply(lambda x:set_output(func[fun_name](x['TARGET'])) )\\\n",
    "                                        .reset_index(level=1,drop=True)\n",
    "                                         .to_dict()\n",
    "                                    })\n",
    "                elif isinstance(func,str):\n",
    "                    col_dict.update({func:X[[col,'TARGET']]\\\n",
    "                                        .groupby([col])\\\n",
    "                                        .apply(lambda x:set_output(func_dict[func](x['TARGET'])) )\\\n",
    "                                        .reset_index(level=1,drop=True)\n",
    "                                        .to_dict()\n",
    "                                    })\n",
    "                else:\n",
    "                    raise NameError('Invalid Format: Function input needs to be either a str or dict(fun_name:fun)')\n",
    "            \n",
    "            self.dictionaries[col] = col_dict\n",
    "        # drop TARGET - column\n",
    "        X = X.drop('TARGET',1)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        for col in self.columns:\n",
    "            dictionary = unravel_tree(self.dictionaries[col],str(col))\n",
    "            for func_key in dictionary.keys():\n",
    "                X[str(func_key)] = X[col].apply(lambda x: dictionary[func_key].get(x,np.nan)).values\n",
    "        if self.drop_old_columns:\n",
    "            X = X.drop(self.columns, 1)\n",
    "        if 'TARGET' in X.columns:\n",
    "            X = X.drop('TARGET',1)\n",
    "        return X\n",
    "\n",
    "def _k_means(x):\n",
    "    n_clust = 2\n",
    "    list_func = ['std']\n",
    "    x = x\n",
    "    if len(x.values)> n_clust+1:\n",
    "        bgm = MiniBatchKMeans(n_clusters=n_clust,random_state=0)\n",
    "        temp_df = pd.DataFrame()\n",
    "        temp_df['clust_label'] = bgm.fit_predict(X=x.values.reshape(-1, 1))\n",
    "        temp_df['TARGET'] = x.values\n",
    "        values_dict = temp_df.groupby(['clust_label']).agg(['mean']+list_func).values\n",
    "        values_list = list(sorted(values_dict,key=lambda y:y[1]) ) \n",
    "        if len(values_list)< (len(list_func)*n_clust):\n",
    "            values_list = np.array([np.nan]*((n_clust-1)*(len(list_func)+1))+ [np.mean(x.values)] + [np.nan]*len(list_func) )\n",
    "            return values_list\n",
    "        return reduce(lambda x,y:x+list(y),values_list,[])\n",
    "    #else\n",
    "    values_list = np.array([np.nan]*((n_clust-1)*(len(list_func)+1))+ [x.values[0]] + [np.nan]*len(list_func) )\n",
    "    return  values_list\n",
    "#_k_means(data_final['delta_minutes'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=10, step=1)\n",
      "0_median_\n",
      "0_mean_\n",
      "0_std_\n",
      "0_ben_\n",
      "1_ben_\n",
      "1_median_\n",
      "1_std_\n",
      "1_mean_\n",
      "2_ben_\n",
      "2_median_\n",
      "2_std_\n",
      "2_mean_\n",
      "3_median_\n",
      "3_mean_\n",
      "3_std_\n",
      "3_ben_\n",
      "4_std_\n",
      "4_ben_\n",
      "4_mean_\n",
      "4_median_\n",
      "5_median_\n",
      "5_std_\n",
      "5_mean_\n",
      "5_ben_\n",
      "6_ben_\n",
      "6_mean_\n",
      "6_std_\n",
      "6_median_\n",
      "7_mean_\n",
      "7_median_\n",
      "7_std_\n",
      "7_ben_\n",
      "8_mean_\n",
      "8_std_\n",
      "8_median_\n",
      "8_ben_\n",
      "9_std_\n",
      "9_mean_\n",
      "9_ben_\n",
      "9_median_\n"
     ]
    }
   ],
   "source": [
    "X,y = prepare_catergorical_data()\n",
    "\n",
    "df = pd.DataFrame(data=X.copy())\n",
    "encoder= FuncEncoder(list_func=['mean','std','median',{'ben':lambda x:x.count() }])\n",
    "\n",
    "X_new = encoder.fit_transform(df,y)\n",
    "for col in X_new.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'b': {0: 83,\n",
       "  1: 62,\n",
       "  2: 31,\n",
       "  3: 68,\n",
       "  4: 116,\n",
       "  5: 120,\n",
       "  6: 146,\n",
       "  7: 99,\n",
       "  8: 46,\n",
       "  9: 168,\n",
       "  10: 106,\n",
       "  11: 152,\n",
       "  12: 108,\n",
       "  13: 81,\n",
       "  14: 21,\n",
       "  15: 35,\n",
       "  17: 132,\n",
       "  18: 69,\n",
       "  19: 23,\n",
       "  20: 32,\n",
       "  21: 23,\n",
       "  22: 36,\n",
       "  34: 39},\n",
       " 'c': {0: 5.1875,\n",
       "  1: 6.2000000000000002,\n",
       "  2: 3.1000000000000001,\n",
       "  3: 5.666666666666667,\n",
       "  4: 7.25,\n",
       "  5: 6.0,\n",
       "  6: 9.125,\n",
       "  7: 9.9000000000000004,\n",
       "  8: 11.5,\n",
       "  9: 10.5,\n",
       "  10: 10.6,\n",
       "  11: 10.857142857142858,\n",
       "  12: 10.800000000000001,\n",
       "  13: 10.125,\n",
       "  14: 10.5,\n",
       "  15: 17.5,\n",
       "  17: 13.199999999999999,\n",
       "  18: 17.25,\n",
       "  19: 11.5,\n",
       "  20: 16.0,\n",
       "  21: 11.5,\n",
       "  22: 18.0,\n",
       "  34: 19.5}}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df[[0,1]].groupby([0]).apply(lambda x:pd.DataFrame({'b':np.sum(x.values),'c':np.mean(x.values)},index={'0':1}) ).reset_index(level=1,drop=True).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "PandasError",
     "evalue": "DataFrame constructor not properly called!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPandasError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-c0aeb9cbe2f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\bendesc\\Anaconda3\\envs\\python35\\lib\\site-packages\\pandas\\core\\groupby.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    692\u001b[0m         \u001b[1;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    693\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0moption_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mode.chained_assignment'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 694\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_apply_general\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    696\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_python_apply_general\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\bendesc\\Anaconda3\\envs\\python35\\lib\\site-packages\\pandas\\core\\groupby.py\u001b[0m in \u001b[0;36m_python_apply_general\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    696\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_python_apply_general\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    697\u001b[0m         keys, values, mutated = self.grouper.apply(f, self._selected_obj,\n\u001b[1;32m--> 698\u001b[1;33m                                                    self.axis)\n\u001b[0m\u001b[0;32m    699\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    700\u001b[0m         return self._wrap_applied_output(\n",
      "\u001b[1;32mC:\\Users\\bendesc\\Anaconda3\\envs\\python35\\lib\\site-packages\\pandas\\core\\groupby.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, data, axis)\u001b[0m\n\u001b[0;32m   1609\u001b[0m             \u001b[1;31m# group might be modified\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1610\u001b[0m             \u001b[0mgroup_axes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_axes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1611\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1612\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_is_indexed_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_axes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m                 \u001b[0mmutated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-50-c0aeb9cbe2f7>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\bendesc\\Anaconda3\\envs\\python35\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    343\u001b[0m                                          copy=False)\n\u001b[0;32m    344\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mPandasError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'DataFrame constructor not properly called!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmgr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPandasError\u001b[0m: DataFrame constructor not properly called!"
     ]
    }
   ],
   "source": [
    "df[[0,1]].groupby([0]).apply(lambda x:pd.DataFrame({np.mean(x.values)},index=0) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
